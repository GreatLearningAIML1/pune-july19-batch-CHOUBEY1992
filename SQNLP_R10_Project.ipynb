{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NLP_Project_Sarcasm_Detection_Questions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pp68FAQf9aMN"},"source":["# Sarcasm Detection\n"," **Acknowledgement**\n","\n","Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n","\n","**Required Files given in below link.**\n","\n","https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S3Wj_mIZ8S3K"},"source":["## Install `Tensorflow2.0` "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jW2Uk8otQvi8","colab":{"base_uri":"https://localhost:8080/","height":777},"executionInfo":{"status":"ok","timestamp":1596371409423,"user_tz":-330,"elapsed":45612,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"40d1c106-0357-4d1d-a768-f8ae65bfa057"},"source":["!!pip uninstall tensorflow\n","!pip install tensorflow==2.0.0"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==2.0.0\n","  Using cached https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n","Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n","Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (2.0.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.5)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.30.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.12.2)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.2)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (49.2.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.17.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.1.1)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n","Installing collected packages: tensorflow\n","Successfully installed tensorflow-2.0.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorflow","tensorflow_core"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v9kv9tyJ77eF"},"source":["## Get Required Files from Drive"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D0O_n6OIEVyL","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596371451764,"user_tz":-330,"elapsed":3068,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"86a4d8b6-f7b4-46d0-cf58-5c81574bfbce"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0mgRpOvFMjKR","colab":{},"executionInfo":{"status":"ok","timestamp":1596371458150,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["#Set your project path \n","project_path = \"/content/drive/My Drive/residency-10/Data/\""],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WXYwajPeQbRq"},"source":["#**## Reading and Exploring Data**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vAk6BRUh8CqL"},"source":["## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n","Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"StSLB-T8PuGr","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1596371459711,"user_tz":-330,"elapsed":1052,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"db4748bf-8679-4b88-e8e7-0934e1451379"},"source":["import pandas as pd\n","article_df = pd.read_json(project_path + \"Sarcasm_Headlines_Dataset.json\", lines=True)\n","article_df.head()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_link</th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://politics.theonion.com/boehner-just-wan...</td>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        article_link  ... is_sarcastic\n","0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n","1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n","2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n","3  https://politics.theonion.com/boehner-just-wan...  ...            1\n","4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z6pXf7A78E2H"},"source":["## Drop `article_link` from dataset. ( 2 marks)\n","As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VLSVsvrlP9qD","colab":{},"executionInfo":{"status":"ok","timestamp":1596371462765,"user_tz":-330,"elapsed":1242,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["article_df = article_df.drop(['article_link'],axis=1)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"bP_KI04zA2nT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1596371462769,"user_tz":-330,"elapsed":849,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"3ce3eb45-eb68-4e3d-a2c9-a36cce2458e1"},"source":["article_df.head()"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            headline  is_sarcastic\n","0  former versace store clerk sues over secret 'b...             0\n","1  the 'roseanne' revival catches up to our thorn...             0\n","2  mom starting to fear son's web series closest ...             1\n","3  boehner just wants wife to listen, not come up...             1\n","4  j.k. rowling wishes snape happy birthday in th...             0"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D0h6IOxU8OdH"},"source":["## Get the Length of each line and find the maximum length. ( 4 marks)\n","As different lines are of different length. We need to pad the our sequences using the max length."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BRAsChZAQmr3","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1596371464607,"user_tz":-330,"elapsed":1205,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"aab4bb0e-4b4a-470c-a823-b4c19eebb593"},"source":["article_df['len'] = article_df['headline'].apply(lambda x: len(x.split(\" \")))\n","article_df.head()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","      <td>11</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            headline  is_sarcastic  len\n","0  former versace store clerk sues over secret 'b...             0   12\n","1  the 'roseanne' revival catches up to our thorn...             0   14\n","2  mom starting to fear son's web series closest ...             1   14\n","3  boehner just wants wife to listen, not come up...             1   13\n","4  j.k. rowling wishes snape happy birthday in th...             0   11"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VPPd0YuPXi2M"},"source":["#**## Modelling**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"35abKfRx8as3"},"source":["## Import required modules required for modelling."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DVel73hYEV4r","colab":{},"executionInfo":{"status":"ok","timestamp":1596371465643,"user_tz":-330,"elapsed":650,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n","from tensorflow.keras.models import Model, Sequential"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9ziybaD1RdD9"},"source":["# Set Different Parameters for the model. ( 2 marks)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jPw9gAN_EV6m","colab":{},"executionInfo":{"status":"ok","timestamp":1596371466811,"user_tz":-330,"elapsed":889,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["max_features = 10000\n","maxlen = 25\n","embedding_size = 200"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9abSe-bM8fn9"},"source":["## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n","Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n","And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T9Ad26HfTFMS","colab":{},"executionInfo":{"status":"ok","timestamp":1596371468429,"user_tz":-330,"elapsed":1572,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(list(df['headline']))"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Ffi63KsST3P"},"source":["# Define X and y for your model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wnjxBdqmSS4s","colab":{"base_uri":"https://localhost:8080/","height":101},"executionInfo":{"status":"ok","timestamp":1596371469409,"user_tz":-330,"elapsed":1581,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"fad32bfc-8a81-4994-8592-69cf2f1e58c7"},"source":["X = tokenizer.texts_to_sequences(df['headline'])\n","X = pad_sequences(X, maxlen = maxlen)\n","y = np.asarray(df['is_sarcastic'])\n","\n","print(\"Number of Samples:\", len(X))\n","print(X[0])\n","print(\"Number of Labels: \", len(y))\n","print(y[0])"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Number of Samples: 26709\n","[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0  307  678 3336 2297   47  381 2575    5 2576 8433]\n","Number of Labels:  26709\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WJLyKg-98rH_"},"source":["## Get the Vocabulary size ( 2 marks)\n","Hint : You can use tokenizer.word_index."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q-2w0gHEUUIo","colab":{},"executionInfo":{"status":"ok","timestamp":1596371582461,"user_tz":-330,"elapsed":1020,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["num_words=len(tokenizer.word_index)+1"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5hjeMi40XcB1"},"source":["#**## Word Embedding**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bUF1TuQa8ux0"},"source":["## Get Glove Word Embeddings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vq5AIfRtMeZh","colab":{},"executionInfo":{"status":"ok","timestamp":1596371585023,"user_tz":-330,"elapsed":1307,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["glove_file = project_path + \"glove.6B.zip\""],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DJLX_n2WMecA","colab":{},"executionInfo":{"status":"ok","timestamp":1596371611454,"user_tz":-330,"elapsed":27320,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["#Extract Glove embedding zip file\n","from zipfile import ZipFile\n","with ZipFile(glove_file, 'r') as z:\n","  z.extractall()"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9IuXlu8-U3HG"},"source":["# Get the Word Embeddings using Embedding file as given below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"elZ-T5aFGZmZ","colab":{},"executionInfo":{"status":"ok","timestamp":1596371634918,"user_tz":-330,"elapsed":30754,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["EMBEDDING_FILE = './glove.6B.200d.txt'\n","\n","embeddings = {}\n","for o in open(EMBEDDING_FILE):\n","    word = o.split(\" \")[0]\n","    # print(word)\n","    embd = o.split(\" \")[1:]\n","    embd = np.asarray(embd, dtype='float32')\n","    # print(embd)\n","    embeddings[word] = embd\n","\n"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bTPxveDmVCrA"},"source":["# Create a weight matrix for words in training docs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xQgOhiywU9nU","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596371634920,"user_tz":-330,"elapsed":29486,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"f96cc8d7-31ca-4858-8186-6b86aa0d525b"},"source":["embedding_matrix = np.zeros((num_words, 200))\n","\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","len(embeddings.values())"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["400000"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u7IbWuEX82Ra"},"source":["## Create and Compile your Model  ( 7 marks)\n","Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n","In the end add a final dense layer with sigmoid activation for binary classification.\n"]},{"cell_type":"code","metadata":{"id":"D7LA3J66Ko5B","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d7jhsSgYXG4l","colab":{},"executionInfo":{"status":"ok","timestamp":1596372212838,"user_tz":-330,"elapsed":2140,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}}},"source":["### Embedding layer for hint \n","model = Sequential()\n","model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n","### Bidirectional LSTM layer for hint \n","model.add(Bidirectional(LSTM(128, return_sequences = True)))\n","model.add(Dense(40, activation=\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(20, activation=\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation=\"sigmoid\"))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IJFMxZwMWoTw"},"source":["# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZpVkajCcWnRK","colab":{"base_uri":"https://localhost:8080/","height":202},"executionInfo":{"status":"ok","timestamp":1596372579456,"user_tz":-330,"elapsed":361066,"user":{"displayName":"Rahul Choubey","photoUrl":"","userId":"14311547828567081650"}},"outputId":"965b9b33-9b14-44b5-ef49-777fe844571a"},"source":["batch_size = 100\n","epochs = 5\n","\n","## Add your code here ##\n","batch_size = 100\n","epochs = 5\n","history = model.fit(X, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Train on 21367 samples, validate on 5342 samples\n","Epoch 1/5\n","21367/21367 [==============================] - 76s 4ms/sample - loss: 0.4839 - accuracy: 0.7632 - val_loss: 0.3475 - val_accuracy: 0.8473\n","Epoch 2/5\n","21367/21367 [==============================] - 71s 3ms/sample - loss: 0.2876 - accuracy: 0.8950 - val_loss: 0.3180 - val_accuracy: 0.8624\n","Epoch 3/5\n","21367/21367 [==============================] - 71s 3ms/sample - loss: 0.2017 - accuracy: 0.9323 - val_loss: 0.3490 - val_accuracy: 0.8611\n","Epoch 4/5\n","21367/21367 [==============================] - 71s 3ms/sample - loss: 0.1398 - accuracy: 0.9547 - val_loss: 0.4284 - val_accuracy: 0.8587\n","Epoch 5/5\n","21367/21367 [==============================] - 71s 3ms/sample - loss: 0.1013 - accuracy: 0.9696 - val_loss: 0.6400 - val_accuracy: 0.8530\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2_hHJYxDMvHF","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}